{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librerie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import produce_pca_files\n",
    "import my_dataset\n",
    "#import my_dataset_norm\n",
    "#import my_dataset_norm2\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import csv\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = produce_pca_files.load_dataset()   #con riduzione pca\n",
    "dataset = my_dataset.load_dataset()           #senza normalizzazione  \n",
    "#dataset = my_dataset_norm.load_dataset()     #con normalizzazione  \n",
    "#datasetN = my_dataset_norm2.load_dataset()    #con nuova normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300, 23100)\n(300,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data.shape)\n",
    "print(dataset.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[37.0 70.0 92.0 ... 19.0 50.0 31.0]\n [30.0 57.0 68.0 ... 20.0 41.0 23.0]\n [39.0 80.0 114.0 ... 36.0 83.0 50.0]\n ...\n [47.0 85.0 117.0 ... 39.0 74.0 38.0]\n [36.0 75.0 95.0 ... 27.0 64.0 37.0]\n [48.0 87.0 108.0 ... 30.0 73.0 43.0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''path = \"D:/test_set\"\n",
    "MAX_LINES = 350\n",
    "def carica_test_set():\n",
    "    \"\"\"\n",
    "    Questo metodo restutuisce il dataset non normalizzato\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    targets = []\n",
    "    for file in os.listdir(path):     #per ogni file video nella cartella\n",
    "        data = []\n",
    "        line_count = 1\n",
    "        with open(path + \"/\" + file) as csv_file:           #apre il file csv\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                if(line_count <= MAX_LINES):        #Inserisce MAX_LINES righe nel dataset\n",
    "                    new_row = [float(i) for i in row]       #Converte in float i valori del file csv\n",
    "                    for element in new_row:\n",
    "                        data.append(element)            #Aggiunge tutti i valori allo stesso array in modo da avere nel Dataset ogni riga (NumpyArray) rappresenti un file csv\n",
    "                    line_count+=1\n",
    "            dataset.append(np.array(data))                  \n",
    "            targets.append(int(file.split('_')[0]))     #Aggiunge il primo valore del nome come etichetta\n",
    "    np_targets = np.array(targets)              #Converte in numpy array\n",
    "    np_dataset = np.array(dataset, dtype=object)        #Converte in numpyarray\n",
    "    return Bunch(data = np_dataset, target = np_targets)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset.data,dataset.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set = carica_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#test_set.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[39.0, 80.0, 114.0, ..., 36.0, 83.0, 50.0],\n",
       "       [43.0, 83.0, 114.0, ..., 35.0, 81.0, 46.0],\n",
       "       [34.0, 59.0, 85.0, ..., 33.0, 79.0, 49.0],\n",
       "       ...,\n",
       "       [31.0, 67.0, 94.0, ..., 28.0, 68.0, 41.0],\n",
       "       [37.0, 77.0, 99.0, ..., 23.0, 65.0, 41.0],\n",
       "       [43.0, 79.0, 104.0, ..., 31.0, 69.0, 39.0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#test_set.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#test_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4, 4, 1, 1, 4, 4, 1, 2, 3, 3, 2, 3, 2, 2, 2, 3, 1, 4, 1, 4, 2, 4,\n",
       "       1, 1, 1, 4, 2, 1, 2, 2, 2, 3, 3, 3, 4, 2, 2, 3, 3, 4, 1, 1, 2, 1,\n",
       "       3, 3, 3, 3, 3, 4, 2, 1, 4, 3, 2, 1, 4, 4, 4, 2, 1, 3, 1, 3, 3, 1,\n",
       "       2, 3, 2, 1, 1, 3, 1, 4, 4, 3, 4, 2, 2, 2, 2, 4, 1, 1, 3, 1, 4, 3,\n",
       "       4, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    " # // indice prova /// con 33 pca\n",
    "#classifier = svm.SVC() #Â  a support vector classifier\n",
    "#classifier = KNeighborsClassifier(1)  \n",
    "#classifier = SVC(kernel=\"linear\", C=0.025) \n",
    "#classifier = SVC(gamma=2, C=1) \n",
    "#classifier = GaussianProcessClassifier()  \n",
    "#classifier = DecisionTreeClassifier(random_state= 0)   #criterion = \"entropy\"\n",
    "#classifier = RandomForestClassifier(random_state = 0)     #or 5 e 10 e 1\n",
    "#classifier = MLPClassifier(alpha=1, max_iter=1000) \n",
    "classifier = AdaBoostClassifier()\n",
    "#classifier = GaussianNB()  \n",
    "#classifier = QuadraticDiscriminantAnalysis() \n",
    "#classifier = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "#classifier = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "classifier.fit(x_train,y_train)\n",
    "#classifier.fit(dataset.data,dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(x_test)\n",
    "#predicted = classifier.predict(test_set.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3111111111111111"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "source": [
    "accuracy_score(predicted,y_test)\n",
    "#accuracy_score(predicted,test_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[1,2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(classifier, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5]})"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "clf.fit(dataset.data,dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.13974171, 0.1352458 , 0.13710656, 0.13103657, 0.13080382]),\n",
       " 'std_fit_time': array([0.01794109, 0.02277351, 0.01114527, 0.00906619, 0.01510779]),\n",
       " 'mean_score_time': array([0.04038877, 0.04506612, 0.04038053, 0.04607   , 0.04802904]),\n",
       " 'std_score_time': array([0.00351283, 0.00385656, 0.00184188, 0.00323517, 0.00659032]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5}],\n",
       " 'split0_test_score': array([0.1509434 , 0.16981132, 0.16981132, 0.18867925, 0.20754717]),\n",
       " 'split1_test_score': array([0.43396226, 0.47169811, 0.43396226, 0.37735849, 0.37735849]),\n",
       " 'split2_test_score': array([0.32075472, 0.33962264, 0.33962264, 0.39622642, 0.39622642]),\n",
       " 'split3_test_score': array([0.37735849, 0.35849057, 0.33962264, 0.28301887, 0.37735849]),\n",
       " 'split4_test_score': array([0.24528302, 0.28301887, 0.22641509, 0.20754717, 0.24528302]),\n",
       " 'mean_test_score': array([0.30566038, 0.3245283 , 0.30188679, 0.29056604, 0.32075472]),\n",
       " 'std_test_score': array([0.09941087, 0.09869205, 0.09320067, 0.08488469, 0.07825072]),\n",
       " 'rank_test_score': array([3, 1, 4, 5, 2])}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.32452830188679244"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_set.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "accuracy_score(predicted,test_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_n_neighbors',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-20a5c08195e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                   (\"Normalized confusion matrix\", 'true')]\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitles_options\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     disp = plot_confusion_matrix(classifier, x_test, y_test,\n\u001b[0m\u001b[0;32m      5\u001b[0m                                  \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                  normalize=normalize)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(classifier, x_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}